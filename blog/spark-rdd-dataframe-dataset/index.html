<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-blog">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.21">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PK0DHL0FKW"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-PK0DHL0FKW",{anonymize_ip:!0})</script>


<link rel="search" type="application/opensearchdescription+xml" title="Lam Tran" href="/opensearch.xml">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Lam Tran RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Lam Tran Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7172314318777821" async crossorigin="anonymous"></script><title data-rh="true">Differences between Spark RDD, Dataframe and Dataset</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://lam-tran.dev/blog/spark-rdd-dataframe-dataset/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" name="keywords" content="Data Engineering, Web Development, Blog"><meta data-rh="true" name="title" content="Lam Tran"><meta data-rh="true" property="og:title" content="Differences between Spark RDD, Dataframe and Dataset | Lam Tran"><meta data-rh="true" name="description" content="Differences between Spark RDD, Dataframe and Dataset"><meta data-rh="true" property="og:description" content="Differences between Spark RDD, Dataframe and Dataset"><meta data-rh="true" property="og:image" content="https://lam-tran.dev/assets/images/RDD-Dataframe-Dataset-bcdbc9781335a0251713276723599867.svg"><meta data-rh="true" name="twitter:image" content="https://lam-tran.dev/assets/images/RDD-Dataframe-Dataset-bcdbc9781335a0251713276723599867.svg"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-04-03T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/lam1051999"><meta data-rh="true" property="article:tag" content="Bigdata,Spark,Apache"><link data-rh="true" rel="icon" href="/img/lt_logo.ico"><link data-rh="true" rel="canonical" href="https://lam-tran.dev/blog/spark-rdd-dataframe-dataset/"><link data-rh="true" rel="alternate" href="https://lam-tran.dev/blog/spark-rdd-dataframe-dataset/" hreflang="en"><link data-rh="true" rel="alternate" href="https://lam-tran.dev/blog/spark-rdd-dataframe-dataset/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://GIW3CHZWR8-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.b7fe553f.css">
<link rel="preload" href="/assets/js/runtime~main.c734677e.js" as="script">
<link rel="preload" href="/assets/js/main.6dac1025.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/lt_logo.svg" alt="TL Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/lt_logo.svg" alt="TL Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Lam Tran</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">About</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/spark-rdd-dataframe-dataset/">Differences between Spark RDD, Dataframe and Dataset</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/how-is-memory-managed-in-spark/">How Is Memory Managed In Spark?</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/state-management-react/">State Management In React</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/mini-spark3-authorizer-part-2/">Authorize Spark 3 SQL With Apache Ranger Part 2 - Integrate Spark SQL With Ranger</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/mini-spark3-authorizer-part-1/">Authorize Spark 3 SQL With Apache Ranger Part 1 - Ranger installation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/spark-catalyst-optimizer-and-spark-session-extension/">Spark Catalyst Optimizer And Spark Session Extension</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/mysql-series-mysql-indexing/">MySQL series - Indexing</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/mysql-series-mysql-mvcc/">MySQL series - Multiversion concurrency control</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/mysql-series-mysql-transaction/">MySQL series - Transaction In MySQL</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/mysql-series-mysql-architecture/">MySQL series - MySQL Architecture Overview</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/spark-kafka-docker/">Create A Data Streaming Pipeline With Spark Streaming, Kafka And Docker</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/spark-cluster-docker/">Create A Standalone Spark Cluster With Docker</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/avl-tree/">AVL Tree, AVL Sorting Algorithm</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/binarysearch-tree/">Binary Search Tree</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/sorting-algorithms/">Fundamental Sorting Algorithms</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/peak-finding/">Peak Finding Algorithm</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_Ikge" itemprop="headline">Differences between Spark RDD, Dataframe and Dataset</h1><div class="blogPostData_SAv4 margin-vert--md"><time datetime="2024-04-03T00:00:00.000Z" itemprop="datePublished">April 3, 2024</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_sTYa"><div class="avatar margin-bottom--sm"><a href="https://github.com/lam1051999" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/lam1051999.png" alt="Lam Tran"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/lam1051999" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Lam Tran</span></a></div><small class="avatar__subtitle" itemprop="description">Data Engineer</small></div></div></div></div></header><meta itemprop="image" content="https://lam-tran.dev/assets/images/RDD-Dataframe-Dataset-bcdbc9781335a0251713276723599867.svg"><div id="post-content" class="markdown" itemprop="articleBody"><p>I have participated in fews technical interviews and have discussed with people topics around data engineering and things they have done in the past. Most of them are familiar with Apache Spark, obviously, one of the most adopted frameworks for big data processing. What I have been asked and what I often ask them is simple concepts around RDD, Dataframe, and Dataset and the differences between them. It sounds quite fundamental, right? Not really. If we have more closer look at them, there are lots of interesting things that can help us understand and choose which is the best suited for our project.</p><p><img loading="lazy" alt="banner image" src="/assets/images/RDD-Dataframe-Dataset-bcdbc9781335a0251713276723599867.svg" width="1284" height="357" class="img_ev3q"></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="1-the-overview">1. The overview<a class="hash-link" href="#1-the-overview" title="Direct link to heading">​</a></h2><table class="tg"><thead><tr><th class="tg-0pky"></th><th class="tg-0pky">RDD</th><th class="tg-0pky">Dataframe</th><th class="tg-0pky">Dataset</th></tr></thead><tbody><tr><td class="tg-0pky">Data representation</td><td class="tg-0pky">A distributed collection of data elements spread across many machines in the cluster. RDDs are a set of Java or Scala objects representing data</td><td class="tg-0pky">A distributed collection of data organized into named columns. It is conceptually equal to a table in a relational database</td><td class="tg-0pky">An extension of Dataframe API that provides the functionality of type-safe, object-oriented programming interface of the RDD API and performance benefits of the Catalyst query optimizer and off heap storage mechanism of a Dataframe API</td></tr><tr><td class="tg-0pky">Data formats</td><td class="tg-0pky">Can easily and efficiently process data which is structured as well as unstructured. But unlike Dataframe and Dataset, RDD does not infer the schema of the ingested data and requires the user to specify it</td><td class="tg-0pky">It works only on structured and semi-structured data. It organizes the data in the named column. Dataframe allows the Spark to manage schema</td><td class="tg-0pky">It also efficiently processes structured and unstructured data. It represents data in the form of JVM objects of row or a collection of row object. Which is represented in tabular forms through encoders</td></tr><tr><td class="tg-0pky">Data source APIs</td><td class="tg-0pky">Data source API allows that an RDD could come from any data source e.g. text file, a database via JDBC etc. and easily handle data with no predefined structure</td><td class="tg-0pky">Data source API allows data processing in different formats (AVRO, CSV, JSON, and storage system HDFS, HIVE tables, MySQL). It can read and write from various data sources that are mentioned above</td><td class="tg-0pky">Dataset API of Spark also support data from different sources</td></tr><tr><td class="tg-0pky">Compile time type safety </td><td class="tg-0pky">RDD provides a familiar object-oriented programming style with compile-time type safety</td><td class="tg-0pky">If you are trying to access the column which does not exist in the table in such case Dataframe APIs does not support compile-time error. It detects attribute error only at runtime</td><td class="tg-0pky">It provides compile-time type safety</td></tr><tr><td class="tg-0pky">Optimization</td><td class="tg-0pky">No inbuilt optimization engine is available in RDD. When working with structured data, RDDs cannot take advantages of Sparks advance optimizers. For example, Catalyst optimizer and Tungsten execution engine. Developers optimise each RDD on the basis of its attributes</td><td class="tg-0pky">Optimization takes place using catalyst optimizer which contains four phases optimization stages</td><td class="tg-0pky">It includes the concept of Dataframe Catalyst optimizer for optimizing query plan</td></tr><tr><td class="tg-0pky">Serialization</td><td class="tg-0pky">Whenever Spark needs to distribute the data within the cluster or write the data to disk, it does so use Java serialization. The overhead of serializing individual Java and Scala objects is expensive and requires sending both data and structure between nodes</td><td class="tg-0pky">Spark Dataframe can serialize the data into off-heap storage (in memory) in binary format and then perform many transformations directly on this off heap memory because Spark understands the schema. There is no need to use java serialization to encode the data. It provides a Tungsten physical execution backend which explicitly manages memory and dynamically generates bytecode for expression evaluation</td><td class="tg-0pky">When it comes to serializing data, the Dataset API in Spark has the concept of an encoder which handles conversion between JVM objects to tabular representation. It stores tabular representation using Spark internal Tungsten binary format. Dataset allows performing the operation on serialized data and improving memory use. It allows on-demand access to individual attribute without deserializing the entire object</td></tr><tr><td class="tg-0pky">Garbage collection</td><td class="tg-0pky">There is overhead for garbage collection that results from creating and destroying individual objects</td><td class="tg-0pky">Avoids the garbage collection costs in constructing individual objects for each row in the dataset</td><td class="tg-0pky">There is also no need for the garbage collector to destroy object because serialization takes place through Tungsten. That uses off heap data serialization</td></tr><tr><td class="tg-0pky">Memory usage</td><td class="tg-0pky">Efficiency is decreased when serialization is performed individually on a java and scala object which takes lots of time</td><td class="tg-0pky">Use of off heap memory for serialization reduces the overhead. It generates byte code dynamically so that many operations can be performed on that serialized data. No need for deserialization for small operations</td><td class="tg-0pky">It allows performing an operation on serialized data and improving memory use. Thus it allows on-demand access to individual attribute without deserializing the entire object</td></tr><tr><td class="tg-0pky">Schema projection</td><td class="tg-0pky">In RDD APIs use schema projection is used explicitly. Hence, we need to define the schema (manually)</td><td class="tg-0pky">Auto-discovering the schema from the files and exposing them as tables through the Hive Meta store. We did this to connect standard SQL clients to our engine. And explore our dataset without defining the schema of our files</td><td class="tg-0pky">Auto discover the schema of the files because of using Spark SQL engine</td></tr><tr><td class="tg-0pky">Aggregation</td><td class="tg-0pky">RDD API is slower to perform simple grouping and aggregation operations</td><td class="tg-0pky">Dataframe API is very easy to use. It is faster for exploratory analysis, creating aggregated statistics on large datasets</td><td class="tg-0pky">Dataset is fast on performing aggregation operations on large amount of data</td></tr><tr><td class="tg-0pky">Use case</td><td class="tg-0pky">You need fine-grained control, low-level transformation over data operations<br>Your data is unstructured, like text streams or media<br>You prefer functional programming constructs for data manipulation over domain-specific functions<br>Defining a schema (like columnar format) isn&#x27;t important during processing<br>You prioritize direct access to data by index or position rather than named columns</td><td class="tg-0pky">You want high-level data manipulation, rich semantics and powerful abstractions, making data processing more intuitive<br>You prefer domain-specific APIs for tasks like filtering, mapping, aggregation (averages, sums), and SQL-like queries<br>You have more efficient data access using column names (instead of indexes) and leverage columnar storage for faster processing<br>The API remains consistent across various Spark libraries, simplifying development<br>Your transformations are complex and need the help of Spark optimizers for improving performance</td><td class="tg-0pky">You prefer features from Dataframe and also higher degree of type-safety at compile time</td></tr></tbody></table><p>*<em>Dataset is not available in PySpark since Python is dynamically typed programming language.</em></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="2-more-about-the-performance-comparision">2. More about the performance comparision<a class="hash-link" href="#2-more-about-the-performance-comparision" title="Direct link to heading">​</a></h2><p>When PySpark interact with RDD, at the driver, <code>SparkContext</code> will use <code>Py4J</code> to launch a JVM and initiate <code>JavaSparkContext</code> and each transformed RDD will associate with <code>PythonRDD</code> objects in Java. When the tasks is distributed to worker nodes, <code>PythonRDD</code> objects run Python subprocesses using pipes, send both code and data to be processed within Python. While this approach allows PySpark to distribute the processing of the data to multiple Python subprocesses on multiple workers, the overall operation will cause a lot of context switches and communications between Java and Python, so there are more overhead to run the code and therefore it is slow when interact with RDD in Python.</p><p><img loading="lazy" alt="pyspark rdd" src="/assets/images/pyspark-RDD-b2984f7fed7968fbe9df8a2f560bd58d.svg" width="1462" height="526" class="img_ev3q"></p><p>On the other hand, Spark Dataframe have a significant advantage - their execution is automatically optimized by a query optimizer component.</p><p>Before any computations are performed on a DataFrame, the Catalyst Optimizer analyzes the sequence of operations used to construct the DataFrame. It then generates an optimized physical execution plan. The optimizer leverages its understanding of the operation semantics and the data structure to make intelligent decisions that can reorganize and optimize the execution plan, leading to more efficient computations compared to executing the operations naively. You can find more about Catalyst Optimizer in <strong><a href="/blog/spark-catalyst-optimizer-and-spark-session-extension/">Spark Catalyst Optimizer And Spark Session Extension</a></strong>.</p><p><img loading="lazy" alt="performance rdd dataframe" src="/assets/images/performance-RDD-Dataframe-26dde4a371d2bb6ed1c66a0ee5ad6bc5.png" width="1024" height="457" class="img_ev3q"></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="3-references">3. References<a class="hash-link" href="#3-references" title="Direct link to heading">​</a></h2><p><a href="https://www.databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html" target="_blank" rel="noopener noreferrer">A Tale of Three Apache Spark APIs: RDDs vs DataFrames and Datasets</a></p><p><a href="https://phoenixnap.com/kb/rdd-vs-dataframe-vs-dataset" target="_blank" rel="noopener noreferrer">RDD vs. DataFrame vs. Dataset</a></p><p><a href="https://www.slideshare.net/hkarau/improving-pyspark-performance-spark-performance-beyond-the-jvm" target="_blank" rel="noopener noreferrer">Improving PySpark Performance Beyond the JVM</a></p><p><a href="https://medium.com/analytics-vidhya/how-does-pyspark-work-step-by-step-with-pictures-c011402ccd57" target="_blank" rel="noopener noreferrer">How does PySpark work? — step by step (with pictures)</a></p><p><a href="https://www.databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html" target="_blank" rel="noopener noreferrer">Introducing DataFrames in Apache Spark for Large Scale Data Science</a></p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_u0Nl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/bigdata">Bigdata</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/spark">Spark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/apache">Apache</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/lam1051999/blogs/edit/main/blog/2024-04-03-spark-rdd-dataframe-dataset/index.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_eYIM" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><div class="margin-vert--xl"></div><div class="margin-vert--lg" style="display:flex;align-items:center;justify-content:center"><a aria-label="Twitter" class="button button--link" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Flam-tran.dev%2Fblog%2Fspark-rdd-dataframe-dataset%2F&amp;text=I%20just%20read%20%22Differences%20between%20Spark%20RDD%2C%20Dataframe%20and%20Dataset%22%20by%20%40lamtt1005" target="_blank" rel="noreferrer noopener" style="display:inline-flex;align-items:center"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" viewBox="0 0 248 204" height="20" width="20" style="margin-right:7px"><g><path fill="#1D9BF0" d="M221.95,51.29c0.15,2.17,0.15,4.34,0.15,6.53c0,66.73-50.8,143.69-143.69,143.69v-0.04 C50.97,201.51,24.1,193.65,1,178.83c3.99,0.48,8,0.72,12.02,0.73c22.74,0.02,44.83-7.61,62.72-21.66 c-21.61-0.41-40.56-14.5-47.18-35.07c7.57,1.46,15.37,1.16,22.8-0.87C27.8,117.2,10.85,96.5,10.85,72.46c0-0.22,0-0.43,0-0.64 c7.02,3.91,14.88,6.08,22.92,6.32C11.58,63.31,4.74,33.79,18.14,10.71c25.64,31.55,63.47,50.73,104.08,52.76 c-4.07-17.54,1.49-35.92,14.61-48.25c20.34-19.12,52.33-18.14,71.45,2.19c11.31-2.23,22.15-6.38,32.07-12.26 c-3.77,11.69-11.66,21.62-22.2,27.93c10.01-1.18,19.79-3.86,29-7.95C240.37,35.29,231.83,44.14,221.95,51.29z"></path></g></svg>Share on Twitter</a></div><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/how-is-memory-managed-in-spark/"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">How Is Memory Managed In Spark?</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-the-overview" class="table-of-contents__link toc-highlight">1. The overview</a></li><li><a href="#2-more-about-the-performance-comparision" class="table-of-contents__link toc-highlight">2. More about the performance comparision</a></li><li><a href="#3-references" class="table-of-contents__link toc-highlight">3. References</a></li></ul></div></div></div></div></div><div class="footer-wrapper footer--dark"><div class="container margin-vert--lg"><div style="display:flex;justify-content:center"><div style="max-width:650px">I am a highly motivated and passionate data engineer. I often work with Python, Scala, and Java and use the latest big data technologies to solve problems, making tools to improve my and others&#x27; work productivity. I am currently certified with<div style="margin-top:10px"><a aria-label="snowpro-core-certification" target="_blank" rel="noreferrer noopener" href="https://achieve.snowflake.com/572af38a-0a3d-4fbf-959a-1e1dcf36a113"><img alt="Snowpro Core Certification" loading="lazy" style="height:50px;width:50px" src="/img/COF-C02.png"></a><a aria-label="aws-certified-solutions-architect-associate" target="_blank" rel="noreferrer noopener" href="https://www.credly.com/badges/2fe47770-22a6-4a16-8849-3f4c5a170fae/public_url"><img alt="AWS Certified Solutions Architect - Associate" loading="lazy" style="height:50px;width:50px;margin-left:5px" src="/img/SAA-C03.png"></a></div></div><div style="margin-left:30px;min-width:162px"><img alt="avatar" loading="lazy" src="/img/avatar.jpg" style="height:130px;width:136px"><p style="font-size:0.8em;margin-top:1em">Lam Tran<br>Data Engineer</p></div></div></div><div style="display:flex;justify-content:center"><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/">About</a></li><li class="footer__item"><a class="footer__link-item" href="/blog/">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact</div><ul class="footer__items clean-list"><li class="footer__item"><a href="mailto:lam1051999@gmail.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Mail<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_lCJq"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/in/lamtt1005/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Linkedin<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_lCJq"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="tel:+84962007024" target="_blank" rel="noopener noreferrer" class="footer__link-item">Phone<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_lCJq"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/lam1051999/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_lCJq"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Lam Tran. Powered by <a aria-label="Docusaurus" target="_blank" rel="noreferrer noopener" style="color:white;font-weight:bold;" href="https://docusaurus.io/">Docusaurus 2</a></div></div></div></footer></div></div></div>
<script src="/assets/js/runtime~main.c734677e.js"></script>
<script src="/assets/js/main.6dac1025.js"></script>
</body>
</html>