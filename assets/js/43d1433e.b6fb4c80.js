"use strict";(self.webpackChunklamtran_blog=self.webpackChunklamtran_blog||[]).push([[9090],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>h});var a=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var p=a.createContext({}),s=function(e){var t=a.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},c=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},g="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),g=s(r),m=n,h=g["".concat(p,".").concat(m)]||g[m]||u[m]||i;return r?a.createElement(h,o(o({ref:t},c),{},{components:r})):a.createElement(h,o({ref:t},c))}));function h(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,o=new Array(i);o[0]=m;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l[g]="string"==typeof e?e:n,o[1]=l;for(var s=2;s<i;s++)o[s]=r[s];return a.createElement.apply(null,o)}return a.createElement.apply(null,r)}m.displayName="MDXCreateElement"},1634:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>g,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var a=r(7462),n=(r(7294),r(3905));const i={slug:"mini-spark3-authorizer-part-1",title:"Authorize Spark 3 SQL With Apache Ranger Part 1 - Ranger installation",description:"Authorize Spark 3 SQL With Apache Ranger Part 1 - Ranger installation",authors:"tranlam",tags:["Bigdata","Spark","Ranger","Apache"],image:"./images/banner.PNG"},o=void 0,l={permalink:"/blog/mini-spark3-authorizer-part-1",editUrl:"https://github.com/lam1051999/blogs/edit/main/blog/2023-04-30-mini-spark3-authorizer-part-1/index.md",source:"@site/blog/2023-04-30-mini-spark3-authorizer-part-1/index.md",title:"Authorize Spark 3 SQL With Apache Ranger Part 1 - Ranger installation",description:"Authorize Spark 3 SQL With Apache Ranger Part 1 - Ranger installation",date:"2023-04-30T00:00:00.000Z",formattedDate:"April 30, 2023",tags:[{label:"Bigdata",permalink:"/blog/tags/bigdata"},{label:"Spark",permalink:"/blog/tags/spark"},{label:"Ranger",permalink:"/blog/tags/ranger"},{label:"Apache",permalink:"/blog/tags/apache"}],readingTime:4.14,truncated:!0,authors:[{name:"Lam Tran",title:"Data Engineer",url:"https://github.com/lam1051999",imageURL:"https://github.com/lam1051999.png",key:"tranlam"}],frontMatter:{slug:"mini-spark3-authorizer-part-1",title:"Authorize Spark 3 SQL With Apache Ranger Part 1 - Ranger installation",description:"Authorize Spark 3 SQL With Apache Ranger Part 1 - Ranger installation",authors:"tranlam",tags:["Bigdata","Spark","Ranger","Apache"],image:"./images/banner.PNG"},prevItem:{title:"Authorize Spark 3 SQL With Apache Ranger Part 2 - Integrate Spark SQL With Ranger",permalink:"/blog/mini-spark3-authorizer-part-2"},nextItem:{title:"Spark Catalyst Optimizer And Spark Session Extension",permalink:"/blog/spark-catalyst-optimizer-and-spark-session-extension"}},p={image:r(9442).Z,authorsImageUrls:[void 0]},s=[],c={toc:s};function g(e){let{components:t,...i}=e;return(0,n.kt)("wrapper",(0,a.Z)({},c,i,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"Spark and Ranger are widely used by many enterprises because of their powerful features. Spark is an in-memory data processing framework and Ranger is a framework to enable, monitor and manage comprehensive data security across the Hadoop platform. Thus, Ranger can be used to do authorization for Spark SQL and this blog will walk you through the integration of those two frameworks. This is the first part of the series, where we install the Ranger framework on our machine, and additionally, Apache Solr for auditing."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"banner",src:r(9442).Z,width:"751",height:"286"})))}g.isMDXComponent=!0},9442:(e,t,r)=>{r.d(t,{Z:()=>a});const a=r.p+"assets/images/banner-f7f67c4c18838de8d49230557182b09d.PNG"}}]);