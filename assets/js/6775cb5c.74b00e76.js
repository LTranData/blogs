"use strict";(self.webpackChunklamtran_blog=self.webpackChunklamtran_blog||[]).push([[7216],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>u});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=r.createContext({}),p=function(e){var t=r.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=p(e.components);return r.createElement(l.Provider,{value:t},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},f=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=p(a),f=n,u=d["".concat(l,".").concat(f)]||d[f]||m[f]||o;return a?r.createElement(u,i(i({ref:t},c),{},{components:a})):r.createElement(u,i({ref:t},c))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,i=new Array(o);i[0]=f;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[d]="string"==typeof e?e:n,i[1]=s;for(var p=2;p<o;p++)i[p]=a[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}f.displayName="MDXCreateElement"},4784:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var r=a(7462),n=(a(7294),a(3905));const o={slug:"spark-rdd-dataframe-dataset/",title:"Differences between Spark RDD, Dataframe and Dataset",description:"Differences between Spark RDD, Dataframe and Dataset",authors:"tranlam",tags:["Bigdata","Spark","Apache"],image:"./images/RDD-Dataframe-Dataset.svg"},i=void 0,s={permalink:"/blog/spark-rdd-dataframe-dataset/",editUrl:"https://github.com/lam1051999/blogs/edit/main/blog/2024-04-17-spark-rdd-dataframe-dataset/index.md",source:"@site/blog/2024-04-17-spark-rdd-dataframe-dataset/index.md",title:"Differences between Spark RDD, Dataframe and Dataset",description:"Differences between Spark RDD, Dataframe and Dataset",date:"2024-04-17T00:00:00.000Z",formattedDate:"April 17, 2024",tags:[{label:"Bigdata",permalink:"/blog/tags/bigdata"},{label:"Spark",permalink:"/blog/tags/spark"},{label:"Apache",permalink:"/blog/tags/apache"}],readingTime:6.925,truncated:!0,authors:[{name:"Lam Tran",title:"Data Engineer",url:"https://github.com/lam1051999",imageURL:"https://github.com/lam1051999.png",key:"tranlam"}],frontMatter:{slug:"spark-rdd-dataframe-dataset/",title:"Differences between Spark RDD, Dataframe and Dataset",description:"Differences between Spark RDD, Dataframe and Dataset",authors:"tranlam",tags:["Bigdata","Spark","Apache"],image:"./images/RDD-Dataframe-Dataset.svg"},nextItem:{title:"How Is Memory Managed In Spark?",permalink:"/blog/how-is-memory-managed-in-spark/"}},l={image:a(7176).Z,authorsImageUrls:[void 0]},p=[],c={toc:p};function d(e){let{components:t,...o}=e;return(0,n.kt)("wrapper",(0,r.Z)({},c,o,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"I have participated in fews technical interviews and have discussed with people topics around data engineering and things they have done in the past. Most of them are familiar with Apache Spark, obviously, one of the most adopted frameworks for big data processing. What I have been asked and what I often ask them is simple concepts around RDD, Dataframe, and Dataset and the differences between them. It sounds quite fundamental, right? Not really. If we have more closer look at them, there are lots of interesting things that can help us understand and choose which is the best suited for our project."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"banner image",src:a(7176).Z,width:"1284",height:"357"})))}d.isMDXComponent=!0},7176:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/RDD-Dataframe-Dataset-bcdbc9781335a0251713276723599867.svg"}}]);