"use strict";(self.webpackChunklamtran_blog=self.webpackChunklamtran_blog||[]).push([[4514],{3905:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>g});var a=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},o=Object.keys(e);for(a=0;a<o.length;a++)r=o[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)r=o[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var c=a.createContext({}),s=function(e){var t=a.useContext(c),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},p=function(e){var t=s(e.components);return a.createElement(c.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,o=e.originalType,c=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=s(r),d=n,g=u["".concat(c,".").concat(d)]||u[d]||m[d]||o;return r?a.createElement(g,i(i({ref:t},p),{},{components:r})):a.createElement(g,i({ref:t},p))}));function g(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=r.length,i=new Array(o);i[0]=d;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l[u]="string"==typeof e?e:n,i[1]=l;for(var s=2;s<o;s++)i[s]=r[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,r)}d.displayName="MDXCreateElement"},7567:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>s});var a=r(7462),n=(r(7294),r(3905));const o={slug:"spark-cluster-docker/",title:"Create A Standalone Spark Cluster With Docker",description:"Create A Standalone Spark Cluster With Docker",authors:"tranlam",tags:["Bigdata","Spark","Apache","Docker"],image:"./images/cluster-overview.PNG"},i=void 0,l={permalink:"/blog/spark-cluster-docker/",editUrl:"https://github.com/LTranData/blogs/edit/main/blog/2022-01-01-spark-cluster-docker/index.md",source:"@site/blog/2022-01-01-spark-cluster-docker/index.md",title:"Create A Standalone Spark Cluster With Docker",description:"Create A Standalone Spark Cluster With Docker",date:"2022-01-01T00:00:00.000Z",formattedDate:"January 1, 2022",tags:[{label:"Bigdata",permalink:"/blog/tags/bigdata"},{label:"Spark",permalink:"/blog/tags/spark"},{label:"Apache",permalink:"/blog/tags/apache"},{label:"Docker",permalink:"/blog/tags/docker"}],readingTime:6.415,truncated:!0,authors:[{name:"Lam Tran",title:"Data Engineer",url:"https://github.com/LTranData",imageURL:"https://github.com/LTranData.png",key:"tranlam"}],frontMatter:{slug:"spark-cluster-docker/",title:"Create A Standalone Spark Cluster With Docker",description:"Create A Standalone Spark Cluster With Docker",authors:"tranlam",tags:["Bigdata","Spark","Apache","Docker"],image:"./images/cluster-overview.PNG"},prevItem:{title:"Create A Data Streaming Pipeline With Spark Streaming, Kafka And Docker",permalink:"/blog/spark-kafka-docker/"},nextItem:{title:"M\u1ed9t s\u1ed1 c\xe2u h\u1ecfi ph\u1ecfng v\u1ea5n AI/ML",permalink:"/blog/ai-interview-questions/"}},c={image:r(7680).Z,authorsImageUrls:[void 0]},s=[],p={toc:s};function u(e){let{components:t,...o}=e;return(0,n.kt)("wrapper",(0,a.Z)({},p,o,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Cluster Overview",src:r(7680).Z,width:"596",height:"286"})),(0,n.kt)("p",null,"Lately, I've spent a lot of time teaching myself how to build Hadoop clusters, Spark, Hive integration, and more. This article will write about how you can build a Spark cluster for data processing using Docker, including 1 master node and 2 worker nodes, the cluster type is standalone cluster (maybe the upcoming articles I will do about Hadoop cluster and integrated resource manager is Yarn). Let's go to the article."))}u.isMDXComponent=!0},7680:(e,t,r)=>{r.d(t,{Z:()=>a});const a=r.p+"assets/images/cluster-overview-e73d0350f6f913d028c171532a18cc2a.PNG"}}]);