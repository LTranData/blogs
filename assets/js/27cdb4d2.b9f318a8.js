"use strict";(self.webpackChunklamtran_blog=self.webpackChunklamtran_blog||[]).push([[1818],{3905:(e,t,a)=>{a.d(t,{Zo:()=>s,kt:()=>u});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function c(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=r.createContext({}),p=function(e){var t=r.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},s=function(e){var t=p(e.components);return r.createElement(l.Provider,{value:t},e.children)},m="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},k=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,l=e.parentName,s=c(e,["components","mdxType","originalType","parentName"]),m=p(a),k=n,u=m["".concat(l,".").concat(k)]||m[k]||g[k]||i;return a?r.createElement(u,o(o({ref:t},s),{},{components:a})):r.createElement(u,o({ref:t},s))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,o=new Array(i);o[0]=k;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c[m]="string"==typeof e?e:n,o[1]=c;for(var p=2;p<i;p++)o[p]=a[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,a)}k.displayName="MDXCreateElement"},170:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>c,toc:()=>p});var r=a(7462),n=(a(7294),a(3905));const i={slug:"spark-kafka-docker/",title:"Create A Data Streaming Pipeline With Spark Streaming, Kafka And Docker",description:"Create A Data Streaming Pipeline With Spark Streaming, Kafka And Docker",authors:"tranlam",tags:["Bigdata","Spark","Apache","Kafka","Docker"],image:"./images/architecture.PNG"},o=void 0,c={permalink:"/blog/spark-kafka-docker/",editUrl:"https://github.com/LTranData/blogs/edit/main/blog/2022-09-11-spark-kafka-docker/index.md",source:"@site/blog/2022-09-11-spark-kafka-docker/index.md",title:"Create A Data Streaming Pipeline With Spark Streaming, Kafka And Docker",description:"Create A Data Streaming Pipeline With Spark Streaming, Kafka And Docker",date:"2022-09-11T00:00:00.000Z",formattedDate:"September 11, 2022",tags:[{label:"Bigdata",permalink:"/blog/tags/bigdata"},{label:"Spark",permalink:"/blog/tags/spark"},{label:"Apache",permalink:"/blog/tags/apache"},{label:"Kafka",permalink:"/blog/tags/kafka"},{label:"Docker",permalink:"/blog/tags/docker"}],readingTime:8.715,truncated:!0,authors:[{name:"Lam Tran",title:"Data Engineer",url:"https://github.com/LTranData",imageURL:"https://github.com/LTranData.png",key:"tranlam"}],frontMatter:{slug:"spark-kafka-docker/",title:"Create A Data Streaming Pipeline With Spark Streaming, Kafka And Docker",description:"Create A Data Streaming Pipeline With Spark Streaming, Kafka And Docker",authors:"tranlam",tags:["Bigdata","Spark","Apache","Kafka","Docker"],image:"./images/architecture.PNG"},prevItem:{title:"MySQL series - MySQL Architecture Overview",permalink:"/blog/mysql-series-mysql-architecture/"},nextItem:{title:"Create A Standalone Spark Cluster With Docker",permalink:"/blog/spark-cluster-docker/"}},l={image:a(1920).Z,authorsImageUrls:[void 0]},p=[],s={toc:p};function m(e){let{components:t,...i}=e;return(0,n.kt)("wrapper",(0,r.Z)({},s,i,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Architecture",src:a(1920).Z,width:"1536",height:"864"})),(0,n.kt)("p",null,"Hi guys, I'm back after a long time without writing anything. Today, I want to share about how to create a Spark Streaming pipeline that consumes data from Kafka, everything is built on Docker."))}m.isMDXComponent=!0},1920:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/architecture-471348c91f3a155a279fc41ef65512c7.PNG"}}]);